# Анализ востребованных компетенций IT-специалистов

В рамках дипломной работы в университете мною было проведено исследование
компетентностного профиля востребованного специалиста в цифровой экономике.

Эмпирическая часть исследования содержала анализ вакансий IT-специалистов
с сайта hh.ru с помощью метода LDA.


### Этапы работы 
1. Выгрузка всех вакансий IT-специалистов с hh.ru. Из-за ограничений 
бесплатной версии API сайта (максимальная глубина запроса – 2000 вакансий и отсутствие возможности выгрузки 
сразу полного текста вакансий), работа проводилась в три этапа:
   - Выгрузка вакансий с применением цикла, включающего несколько итераций по различным категориям, таким как регион, отрасль, роль, график работы, опыт работы и тип занятости, чтобы обойти ограничение по глубине запроса 
   - С помощью списка id вакансий, полученных на первом этапе, выгрузка полных текстов вакансий в формате json
   - Обработка полных текстов вакансий и выделение из них требований и обязанностей на основе данных первого этапа
2. Дальнейшим этапом была подготовка данных о требованиях к кандидатам к применению LDA. Все слова были 
приведены к нижнему регистру, с помощью регулярных выражений удалена пунктуация и цифры, а с помощью пакета pymorphy2  
произведена лемматизация слов, с целью приведения их к изначальной форме. Далее были удалены стоп-слова типичные для 
русского языка (предлоги, союзы, междометья, местоимения и пр.). Так как для рынка труда отсутствует список стандартных 
стоп-слов, они были удалены опытным путем при прогонке модели LDA. 
3. Для векторизации использовался CountVectorizer из библиотеки scikit-learn , с параметрами analyzer='word' 
(токенами служат слова), min_df=50 (слова, встречающиеся менее, чем в 50 документах, удаляются). 
Стоит отдельно упомянуть, что биграммы и триграммы не использовались в итоговой модели, так как показывали худший результат.
4. Модель Latent Dirichlet Allocation (LDA) была использована также из библиотеки scikit-learn, поскольку в результате 
визуальной оценки она продемонстрировала более удачные результаты по сравнению с моделью из библиотеки gensim , 
даже при различных настройках обширного числа параметров модели gensim.
5. Полученные темы были подвергнуты двойной группировке. В первую очередь, темы были объединены путем обобщения связанных компетенций. Это было необходимо, так как некоторые компетенции оказались слишком узкоспециализированными и специфичными для определенных профессиональных областей, в то время как основная цель исследования заключалась в выявлении востребованных компетенций на рынке информационных технологий в целом.  В дальнейшем будем называть эти объединенные компетенции группами узкопрофессиональных компетенций. 
Затем было принято решение пересмотреть подход и описать востребованные компетенции в более широких, общих терминах, которые применимы к любому рынку труда, для этого выделенные компетенции были снова сгруппированы в группы универсальных  компетенций. Дальнейший анализ производился как для узкопрофессиональных компетенций, так и для универсальных групп. 
6. Анализ востребованных компетенций, как в целом в отрасли, так и для отдельных групп в зависимости от графика, опыта работы, 
заработной платы, региона и отрасли.

### Структура репозитория
Данный репозиторий содержит некоторые важные фрагменты работы:
- **data_collection.py** - код для сбора данных вакансий с hh.ru;
- **processing_full_texts.py** - выделение требований и обязанностей из полных текстов вакансий;
- **preprocessing_and_modeling.py** - предобработка текстовых данных и создание итоговой модели LDA;
- **analysis.ipynb** - часть анализа, включающая анализ востребованных групп универсальных компетенций для всей сферы IT, а
также для групп по различным переменным (график, опыт, регион и пр.).

### Результаты
Более подробное описание методологии и результатов исследования можно найти в тексте выпускной квалификационной работы (пока не опубликован). Данный репозиторий предоставляет краткий обзор проведенной работы и содержит основные результаты по одной из моделей.

### Примечания
Работа является более масштабной и включает множество промежуточных этапов обработки данных и настройки моделей, которые не включены в данный репозиторий. Можно сказать, что репозиторий представляет собой своего рода саммери выполненной работы ☺


